{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZohaibCodez/openai-agents-chainlit-lab/blob/main/01_hello_agent/async/hello_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUVPp9cmsmpc"
      },
      "source": [
        "# Running Google's Gemini using run with OpenAI Agents SDK in Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F16KTq4RsyNx"
      },
      "source": [
        "## Installing OpenAI Agents SDk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eMo8xvUsrie",
        "outputId": "080dffb8-e5e5-44af-9ab1-a9d2b35bc5e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/121.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB4-s1oDsuH5"
      },
      "source": [
        "## Making Jupyter Notebook capable of running asynchronous functions like our RunLoopEvent(Runner.run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cMddCPyxs3gJ"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36OVBSUzs56P"
      },
      "source": [
        "## Running Google's GEMINI with OpenAI Agents SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3Fbq7Eces8yB"
      },
      "outputs": [],
      "source": [
        "from agents import Agent,Runner,AsyncOpenAI,OpenAIChatCompletionsModel,RunResult\n",
        "from agents.run import RunConfig\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lW95w-1-s-oU"
      },
      "outputs": [],
      "source": [
        "gemini_api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "if not gemini_api_key:\n",
        "  raise ValueError(\"GEMINI_API_KEY is not set. Please ensure it is set\")\n",
        "\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        "    )\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model = \"gemini-2.0-flash\",\n",
        "    openai_client = external_client\n",
        ")\n",
        "\n",
        "run_config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=external_client,\n",
        "    tracing_disabled=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFFIvZv0tc6O"
      },
      "source": [
        "## Hello World Code | Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97sMQWDXthbW",
        "outputId": "b85c57ea-1f15-47f7-9f8f-d4e3cecee023"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! How can I help you today?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "agent:Agent = Agent(name=\"Assistant\",instructions = \"You are an agent - please keep going until the user’s query is completely resolved, before ending your turn and yielding back to the user. Only terminate your turn when you are sure that the problem is solved.\",model=model)\n",
        "\n",
        "result:RunResult = Runner.run_sync(starting_agent=agent,input=\"Hello...!\",run_config=run_config)\n",
        "print(result.final_output)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
