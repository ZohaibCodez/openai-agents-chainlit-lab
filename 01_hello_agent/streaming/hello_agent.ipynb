{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZohaibCodez/openai-agents-chainlit-lab/blob/main/01_hello_agent/streaming/hello_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf0_mQZZ1MwY"
      },
      "source": [
        "# Running Google's Gemini using run_streamed with OpenAI Agents SDK in Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing OpenAI Agents SDk"
      ],
      "metadata": {
        "id": "EfL8Q4GJ2WCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai-agents"
      ],
      "metadata": {
        "id": "ftqmj8O02gIn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making Jupyter Notebook capable of running asynchronous functions like our RunLoopEvent(Runner.run_streamed)"
      ],
      "metadata": {
        "id": "mqA05vEE2hof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "Rh3ymgs72l2A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running Google's GEMINI with OpenAI Agents SDK"
      ],
      "metadata": {
        "id": "vhmhBidK2nnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent,Runner,AsyncOpenAI,OpenAIChatCompletionsModel,RunResult\n",
        "from agents.run import RunConfig\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "uVKVtNve2pZ3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "if not gemini_api_key:\n",
        "  raise ValueError(\"GEMINI_API_KEY is not set. Please ensure it is set\")\n",
        "\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        "    )\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model = \"gemini-2.0-flash\",\n",
        "    openai_client = external_client\n",
        ")\n",
        "\n",
        "run_config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=external_client,\n",
        "    tracing_disabled=True\n",
        ")"
      ],
      "metadata": {
        "id": "S_0QoKXU2sQh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hello World Code | Run"
      ],
      "metadata": {
        "id": "bvZN851o2vc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from openai.types.responses import ResponseTextDeltaEvent\n",
        "\n",
        "async def main():\n",
        "  agent:Agent = Agent(name=\"Assistant\",instructions = \"You are an agent - please keep going until the userâ€™s query is completely resolved, before ending your turn and yielding back to the user. Only terminate your turn when you are sure that the problem is solved.\",model=model)\n",
        "\n",
        "  result:RunResult =Runner.run_streamed(starting_agent=agent,input=\"Hello...! My name is Zohaib\",run_config=run_config)\n",
        "  async for event in result.stream_events():\n",
        "    if event.type == \"raw_response_event\" and isinstance(event.data,ResponseTextDeltaEvent):\n",
        "      print(event.data.delta,end=\"\",flush=True)\n",
        "\n",
        "  new_input = result.to_input_list() + [{\"role\": \"user\", \"content\": \"What is my name?\"}]\n",
        "\n",
        "  result2:RunResult =Runner.run_streamed(starting_agent=agent,input=new_input,run_config=run_config)\n",
        "  async for event in result2.stream_events():\n",
        "    if event.type == \"raw_response_event\" and isinstance(event.data,ResponseTextDeltaEvent):\n",
        "      print(event.data.delta,end=\"\",flush=True)\n",
        "\n",
        "  new_input2 = result2.to_input_list() + [{\"role\": \"user\", \"content\": \"Tell me 5 jokes about coding\"}]\n",
        "\n",
        "  result2:RunResult =Runner.run_streamed(starting_agent=agent,input=new_input2,run_config=run_config)\n",
        "  async for event in result2.stream_events():\n",
        "    if event.type == \"raw_response_event\" and isinstance(event.data,ResponseTextDeltaEvent):\n",
        "      print(event.data.delta,end=\"\",flush=True)\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4k6ujGP2zdC",
        "outputId": "d9b0acbb-c4ee-42e2-bf62-6371cd16585a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Zohaib! It's nice to meet you. How can I help you today?\n",
            "Your name is Zohaib.\n",
            "Okay, Zohaib, here are 5 coding jokes for you:\n",
            "\n",
            "1.  **Why do programmers prefer dark mode?** Because light attracts bugs!\n",
            "\n",
            "2.  **Why was the JavaScript developer sad?** Because they didn't Node how to Express themselves.\n",
            "\n",
            "3.  **Why did the programmer quit his job?** Because he didn't get arrays.\n",
            "\n",
            "4.  **There are 10 types of people in the world:** Those who understand binary, and those who don't.\n",
            "\n",
            "5.  **Debugging:** Removing the needles from the haystack.\n",
            "\n",
            "Hope you enjoyed those, Zohaib! Let me know if you'd like to hear more.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}